#!/usr/bin/env node

/**
 * å¢å¼ºç‰ˆAIè·¯ç”±å™¨æµ‹è¯•è„šæœ¬
 * æ¼”ç¤ºå¹¶å‘è¯·æ±‚ã€è´Ÿè½½å‡è¡¡å’Œæ™ºèƒ½è·¯ç”±åŠŸèƒ½
 */

const { performance } = require('perf_hooks')

// æ¨¡æ‹Ÿå¢å¼ºç‰ˆAIè·¯ç”±å™¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ç”¨äºæ¼”ç¤ºï¼‰
class MockEnhancedAIRouter {
  constructor() {
    this.services = [
      { id: 'openai', name: 'OpenAI GPT-4', latency: 1500, cost: 0.03, quality: 0.95 },
      { id: 'anthropic', name: 'Claude 3 Sonnet', latency: 1200, cost: 0.015, quality: 0.92 },
      { id: 'openai-fast', name: 'OpenAI GPT-3.5', latency: 800, cost: 0.002, quality: 0.85 }
    ]
    this.requestCount = 0
    this.responseCache = new Map()
  }

  // æ¨¡æ‹Ÿå¹¶å‘è¯·æ±‚å¤„ç†
  async routeConcurrentRequest(request, maxConcurrency = 2) {
    const startTime = performance.now()
    this.requestCount++

    console.log(`ğŸš€ å¤„ç†å¹¶å‘è¯·æ±‚ #${this.requestCount} (å¹¶å‘æ•°: ${maxConcurrency})`)
    console.log(`   æç¤ºè¯: "${request.prompt.substring(0, 50)}..."`)

    // é€‰æ‹©æœ€ä½³æœåŠ¡
    const availableServices = this.services.slice(0, maxConcurrency)
    const promises = availableServices.map(service =>
      this.mockServiceCall(service, request)
    )

    try {
      const results = await Promise.allSettled(promises)
      const successfulResults = results
        .filter(r => r.status === 'fulfilled')
        .map(r => r.value)

      if (successfulResults.length === 0) {
        throw new Error('æ‰€æœ‰å¹¶å‘è¯·æ±‚éƒ½å¤±è´¥äº†')
      }

      // é€‰æ‹©æœ€ä½³ç»“æœ
      const bestResult = successfulResults.reduce((best, current) =>
        current.score > best.score ? current : best
      )

      const responseTime = performance.now() - startTime

      console.log(`âœ… å¹¶å‘è¯·æ±‚æˆåŠŸå®Œæˆ`)
      console.log(`   é€‰æ‹©æä¾›å•†: ${bestResult.service.name}`)
      console.log(`   å“åº”æ—¶é—´: ${responseTime.toFixed(0)}ms`)
      console.log(`   æˆåŠŸç‡: ${successfulResults.length}/${maxConcurrency}`)
      console.log(`   è¯„åˆ†: ${bestResult.score.toFixed(3)}`)

      return {
        requestId: `req_${this.requestCount}`,
        provider: bestResult.service.id,
        model: bestResult.service.name,
        content: bestResult.content,
        responseTime,
        success: true,
        metadata: {
          concurrentResults: {
            totalRequests: maxConcurrency,
            successfulRequests: successfulResults.length,
            selectedProvider: bestResult.service.id
          },
          performanceScore: bestResult.score
        }
      }

    } catch (error) {
      console.log(`âŒ å¹¶å‘è¯·æ±‚å¤±è´¥: ${error.message}`)
      throw error
    }
  }

  // æ¨¡æ‹ŸæœåŠ¡è°ƒç”¨
  async mockServiceCall(service, request) {
    // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, service.latency))

    // æ¨¡æ‹Ÿå¶å‘å¤±è´¥ï¼ˆ5%å¤±è´¥ç‡ï¼‰
    if (Math.random() < 0.05) {
      throw new Error(`${service.name} ä¸´æ—¶ä¸å¯ç”¨`)
    }

    // ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
    const responses = [
      `åŸºäº${service.name}çš„åˆ†æï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„é—®é¢˜ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›è¯¦ç»†çš„è§£ç­”...`,
      `${service.name}è®¤ä¸ºï¼šæ ¹æ®æ‚¨çš„é—®é¢˜ï¼Œæˆ‘å»ºè®®ä»ä»¥ä¸‹å‡ ä¸ªè§’åº¦æ¥è€ƒè™‘...`,
      `${service.name}å›å¤ï¼šç»è¿‡æ·±å…¥æ€è€ƒï¼Œæˆ‘è®¤ä¸ºæœ€ä½³æ–¹æ¡ˆæ˜¯...`
    ]

    const content = responses[Math.floor(Math.random() * responses.length)]

    // è®¡ç®—ç»¼åˆè¯„åˆ†
    const timeScore = Math.max(0, 1 - service.latency / 3000)
    const costScore = Math.max(0, 1 - service.cost / 0.05)
    const score = (service.quality * 0.4) + (timeScore * 0.3) + (costScore * 0.3)

    return {
      service,
      content,
      score,
      usage: {
        promptTokens: Math.floor(Math.random() * 100) + 50,
        completionTokens: Math.floor(Math.random() * 200) + 100,
        estimatedCost: service.cost * (Math.random() * 0.5 + 0.5)
      }
    }
  }

  // æ¨¡æ‹Ÿè´Ÿè½½å‡è¡¡
  async distributeLoad(requests, strategy = 'weighted') {
    console.log(`\nğŸ“Š å¼€å§‹è´Ÿè½½å‡è¡¡æµ‹è¯• (ç­–ç•¥: ${strategy})`)
    console.log(`   è¯·æ±‚æ•°é‡: ${requests.length}`)

    const startTime = performance.now()
    const results = []

    for (let i = 0; i < requests.length; i++) {
      const request = requests[i]

      // æ ¹æ®ç­–ç•¥é€‰æ‹©æœåŠ¡
      let selectedService
      switch (strategy) {
        case 'round-robin':
          selectedService = this.services[i % this.services.length]
          break
        case 'weighted':
          // æƒé‡åŸºäºè´¨é‡å’Œæˆæœ¬
          const weights = this.services.map(s => s.quality / s.cost)
          const totalWeight = weights.reduce((a, b) => a + b, 0)
          let random = Math.random() * totalWeight
          let acc = 0
          for (let j = 0; j < this.services.length; j++) {
            acc += weights[j]
            if (random <= acc) {
              selectedService = this.services[j]
              break
            }
          }
          break
        case 'least-connections':
          // é€‰æ‹©å»¶è¿Ÿæœ€ä½çš„æœåŠ¡
          selectedService = this.services.reduce((min, s) =>
            s.latency < min.latency ? s : min
          )
          break
        default:
          selectedService = this.services[0]
      }

      try {
        const result = await this.mockServiceCall(selectedService, request)
        results.push({
          requestId: `load_${i + 1}`,
          provider: selectedService.id,
          success: true,
          responseTime: selectedService.latency,
          score: result.score,
          content: result.content.substring(0, 100) + '...'
        })
      } catch (error) {
        results.push({
          requestId: `load_${i + 1}`,
          provider: selectedService.id,
          success: false,
          error: error.message
        })
      }
    }

    const totalTime = performance.now() - startTime
    const successCount = results.filter(r => r.success).length

    console.log(`âœ… è´Ÿè½½å‡è¡¡æµ‹è¯•å®Œæˆ`)
    console.log(`   æ€»è€—æ—¶: ${totalTime.toFixed(0)}ms`)
    console.log(`   æˆåŠŸç‡: ${successCount}/${requests.length} (${(successCount/requests.length*100).toFixed(1)}%)`)
    console.log(`   å¹³å‡å“åº”æ—¶é—´: ${(totalTime/requests.length).toFixed(0)}ms`)

    return results
  }

  // æ¨¡æ‹ŸæœåŠ¡é¢„çƒ­
  async warmupServices() {
    console.log(`\nğŸ”¥ å¼€å§‹æœåŠ¡é¢„çƒ­...`)

    const warmupPromises = this.services.map(async (service) => {
      try {
        await this.mockServiceCall(service, { prompt: 'å¥åº·æ£€æŸ¥' })
        console.log(`   âœ… ${service.name} é¢„çƒ­æˆåŠŸ`)
        return { service: service.id, status: 'healthy' }
      } catch (error) {
        console.log(`   âŒ ${service.name} é¢„çƒ­å¤±è´¥: ${error.message}`)
        return { service: service.id, status: 'unhealthy' }
      }
    })

    const results = await Promise.allSettled(warmupPromises)
    const healthyCount = results.filter(r =>
      r.status === 'fulfilled' && r.value.status === 'healthy'
    ).length

    console.log(`ğŸ”¥ é¢„çƒ­å®Œæˆ: ${healthyCount}/${this.services.length} æœåŠ¡å¥åº·`)
    return results
  }

  // è·å–ç»Ÿè®¡ä¿¡æ¯
  getStats() {
    return {
      totalRequests: this.requestCount,
      availableServices: this.services.length,
      cacheSize: this.responseCache.size
    }
  }
}

// æµ‹è¯•å‡½æ•°
async function runTests() {
  console.log('ğŸ¯ å¢å¼ºç‰ˆAIè·¯ç”±å™¨æµ‹è¯•å¼€å§‹\n')

  const router = new MockEnhancedAIRouter()

  // æµ‹è¯•1: æœåŠ¡é¢„çƒ­
  console.log('='.repeat(60))
  console.log('æµ‹è¯•1: æœåŠ¡é¢„çƒ­')
  console.log('='.repeat(60))
  await router.warmupServices()

  // æµ‹è¯•2: å•ä¸ªå¹¶å‘è¯·æ±‚
  console.log('\n' + '='.repeat(60))
  console.log('æµ‹è¯•2: å•ä¸ªå¹¶å‘è¯·æ±‚')
  console.log('='.repeat(60))

  const singleRequest = {
    prompt: 'è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Œä»¥åŠå®ƒåœ¨ç°ä»£ç§‘æŠ€ä¸­çš„åº”ç”¨',
    preferences: { quality: 'excellent', speed: 'fast' }
  }

  await router.routeConcurrentRequest(singleRequest, 2)

  // æµ‹è¯•3: å¤šä¸ªå¹¶å‘è¯·æ±‚
  console.log('\n' + '='.repeat(60))
  console.log('æµ‹è¯•3: å¤šä¸ªå¹¶å‘è¯·æ±‚')
  console.log('='.repeat(60))

  const concurrentRequests = [
    { prompt: 'åˆ†æä¸€ä¸‹åŒºå—é“¾æŠ€æœ¯çš„æœªæ¥å‘å±•å‰æ™¯' },
    { prompt: 'å¦‚ä½•æé«˜è½¯ä»¶å¼€å‘çš„æ•ˆç‡å’Œè´¨é‡ï¼Ÿ' },
    { prompt: 'è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†å’Œåº”ç”¨é¢†åŸŸ' }
  ]

  console.log(`\nå¹¶å‘å¤„ç† ${concurrentRequests.length} ä¸ªè¯·æ±‚...`)
  const concurrentPromises = concurrentRequests.map((req, index) =>
    router.routeConcurrentRequest({
      ...req,
      requestId: `concurrent_${index + 1}`
    }, 2)
  )

  const concurrentResults = await Promise.allSettled(concurrentPromises)
  const concurrentSuccessCount = concurrentResults.filter(r => r.status === 'fulfilled').length
  console.log(`\nğŸ¯ å¹¶å‘è¯·æ±‚ç»“æœ: ${concurrentSuccessCount}/${concurrentRequests.length} æˆåŠŸ`)

  // æµ‹è¯•4: è´Ÿè½½å‡è¡¡æµ‹è¯•
  console.log('\n' + '='.repeat(60))
  console.log('æµ‹è¯•4: è´Ÿè½½å‡è¡¡æµ‹è¯•')
  console.log('='.repeat(60))

  const loadRequests = Array.from({ length: 12 }, (_, i) => ({
    prompt: `è´Ÿè½½æµ‹è¯•è¯·æ±‚ ${i + 1}: è¯·åˆ†æå½“å‰æŠ€æœ¯è¶‹åŠ¿${i + 1}`
  }))

  // æµ‹è¯•ä¸åŒçš„è´Ÿè½½å‡è¡¡ç­–ç•¥
  const strategies = ['round-robin', 'weighted', 'least-connections']

  for (const strategy of strategies) {
    await router.distributeLoad(loadRequests.slice(0, 6), strategy)
    console.log('') // ç©ºè¡Œåˆ†éš”
  }

  // æµ‹è¯•5: æ€§èƒ½å‹åŠ›æµ‹è¯•
  console.log('='.repeat(60))
  console.log('æµ‹è¯•5: æ€§èƒ½å‹åŠ›æµ‹è¯•')
  console.log('='.repeat(60))

  const stressTestStart = performance.now()
  const stressRequests = Array.from({ length: 20 }, (_, i) => ({
    prompt: `å‹åŠ›æµ‹è¯• ${i + 1}: å¿«é€Ÿå›ç­”è¿™ä¸ªé—®é¢˜${i + 1}`
  }))

  console.log(`\nå¼€å§‹å¤„ç† ${stressRequests.length} ä¸ªå‹åŠ›æµ‹è¯•è¯·æ±‚...`)

  const stressPromises = stressRequests.map((req, index) =>
    router.routeConcurrentRequest({
      ...req,
      requestId: `stress_${index + 1}`,
      preferences: { speed: 'fast', cost: 'low' }
    }, 2)
  )

  const stressResults = await Promise.allSettled(stressPromises)
  const stressTestTime = performance.now() - stressTestStart
  const stressSuccessCount = stressResults.filter(r => r.status === 'fulfilled').length

  console.log(`\nğŸ”¥ å‹åŠ›æµ‹è¯•å®Œæˆ`)
  console.log(`   æ€»è¯·æ±‚æ•°: ${stressRequests.length}`)
  console.log(`   æˆåŠŸè¯·æ±‚: ${stressSuccessCount}`)
  console.log(`   æˆåŠŸç‡: ${(stressSuccessCount/stressRequests.length*100).toFixed(1)}%`)
  console.log(`   æ€»è€—æ—¶: ${stressTestTime.toFixed(0)}ms`)
  console.log(`   QPS: ${(stressSuccessCount/(stressTestTime/1000)).toFixed(2)} è¯·æ±‚/ç§’`)
  console.log(`   å¹³å‡å“åº”æ—¶é—´: ${(stressTestTime/stressRequests.length).toFixed(0)}ms`)

  // æœ€ç»ˆç»Ÿè®¡
  console.log('\n' + '='.repeat(60))
  console.log('ğŸ‰ æµ‹è¯•æ€»ç»“')
  console.log('='.repeat(60))

  const finalStats = router.getStats()
  console.log(`æ€»è¯·æ±‚æ•°: ${finalStats.totalRequests}`)
  console.log(`å¯ç”¨æœåŠ¡: ${finalStats.availableServices}`)
  console.log(`ç¼“å­˜æ¡ç›®: ${finalStats.cacheSize}`)

  // æˆåŠŸç‡ç»Ÿè®¡
  const allResults = [...concurrentResults, ...stressResults]
  const totalSuccessCount = allResults.filter(r => r.status === 'fulfilled').length
  const totalRequestsCount = allResults.length

  console.log(`\nğŸ“Š æ€»ä½“æ€§èƒ½æŒ‡æ ‡:`)
  console.log(`   æ€»ä½“æˆåŠŸç‡: ${(totalSuccessCount/totalRequestsCount*100).toFixed(1)}%`)
  console.log(`   å¹¶å‘å¤„ç†èƒ½åŠ›: æ”¯æŒ2-3ä¸ªå¹¶å‘è¯·æ±‚`)
  console.log(`   è´Ÿè½½å‡è¡¡ç­–ç•¥: æ”¯æŒè½®è¯¢ã€æƒé‡ã€æœ€å°‘è¿æ¥ç­–ç•¥`)
  console.log(`   æ™ºèƒ½è·¯ç”±: åŸºäºè´¨é‡ã€é€Ÿåº¦ã€æˆæœ¬çš„åŠ¨æ€é€‰æ‹©`)

  console.log('\nâœ¨ å¢å¼ºç‰ˆAIè·¯ç”±å™¨æµ‹è¯•å®Œæˆï¼')
}

// è¿è¡Œæµ‹è¯•
if (require.main === module) {
  runTests().catch(console.error)
}

module.exports = { MockEnhancedAIRouter, runTests }